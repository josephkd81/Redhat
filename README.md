# Redhat_Practice using XGBoost

## Abstract
- XGBoost에 대해 이해하고, HyperParameter Tuning을 통해 결과값을 개선하는 연습을 해본다.
- 이를 위해 kaggle의 'Predicting Redhat Business Value'라는 프로젝트를 수행한다.
- 프로젝트를 통해 배운 점을 정리하고, 추가과제를 도출한다.

## Background
- 이전 프로젝트인 'shelter animals'에서 최종선택된 모델인 XGBoost
- 모델 자체에 대한 이해 부족
- 도구에 대해서 이해해야, 도구를 개선할 수 있다!

## XGBoost
- Supervised Learning
- CART(classification & Regression trees) : Prediction score in each leaf
- Tree Ensemble / Additive Training
- Objective Function = Trainig Loss + Regularization
- 사용자 정의 손실함수 지원 가능
- Model Complexity
- The Structure Score

## Project Definition
- Predicting Red Hat Business Value in kaggle
- Identifies which customers have the most potential business value for Red Hat based on their characteristics and activities
- Binary classification
- Eval function : auc

## Methods & Process
- EDA
- Preprocessing
- Modeling

## EDA

## Preprocessing

## Modeling

## Results & Discussions

## Conclusion
